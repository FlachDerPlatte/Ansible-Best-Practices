{"config":{"indexing":"full","lang":["de"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s]"},"docs":[{"location":"","text":"Best Practices This document aims to gather good and best practices from Ansible practitioners and projects at Computacenter. It strives to give all Ansible users a guideline from which to start their automation journey in good conditions. Ansible is simple, flexible, and powerful. Like any powerful tool, there are many ways to use it, some better than others. Those are opinionated guidelines based on the experience of many projects. They are not meant to be followed blindly if they don\u2019t fit the reader\u2019s specific use case or needs. Take them as an inspiration and adjust them to your needs, still let us know your good and best practices, we all can learn. Versioning This guide is updated constantly, last update on 13. Dezember 2022 .","title":"Overview"},{"location":"#best-practices","text":"This document aims to gather good and best practices from Ansible practitioners and projects at Computacenter. It strives to give all Ansible users a guideline from which to start their automation journey in good conditions. Ansible is simple, flexible, and powerful. Like any powerful tool, there are many ways to use it, some better than others. Those are opinionated guidelines based on the experience of many projects. They are not meant to be followed blindly if they don\u2019t fit the reader\u2019s specific use case or needs. Take them as an inspiration and adjust them to your needs, still let us know your good and best practices, we all can learn. Versioning This guide is updated constantly, last update on 13. Dezember 2022 .","title":"Best Practices"},{"location":"ansible/","text":"Ansible This topic is split into seven main sections, each section covers a different aspect of automation using Ansible. Installation - How to run Ansible, from present to future Project - Your Ansible project, version control, dependencies, syntax Inventory - How to define your inventory and target hosts Variables - All about variables, where to store them, naming conventions and encryption Playbook - Structure your automation, how to separate playbooks and plays Roles - A best practice in itself, including how to create and fill the role folder Tasks - Everything about tasks, module usage, tags, loops and filters","title":"Ansible"},{"location":"ansible/#ansible","text":"This topic is split into seven main sections, each section covers a different aspect of automation using Ansible. Installation - How to run Ansible, from present to future Project - Your Ansible project, version control, dependencies, syntax Inventory - How to define your inventory and target hosts Variables - All about variables, where to store them, naming conventions and encryption Playbook - Structure your automation, how to separate playbooks and plays Roles - A best practice in itself, including how to create and fill the role folder Tasks - Everything about tasks, module usage, tags, loops and filters","title":"Ansible"},{"location":"ansible/installation/","text":"Installation The latest version can only be obtained via the Python package manager, the ansible-core package contains the binaries and 69 standard modules. pip3 install ansible-core If more special modules are needed, the complete ansible package can be installed, this corresponds to the \"old\" installation method ( batteries included ). pip3 install ansible Tip It makes sense to install only the ansible-core package. Afterwards, install the few collections necessary for your project via ansible-galaxy . This way you have an up-to-date, lean installation without unnecessary modules and plugins. Thereby the chapter Project > Collections is to be considered. If a container runtime is available, the complete installation can also be bundled in a container image (so-called Execution Environment ). Execution environments Execution Environments are container images that serve as Ansible control nodes. Ansible Builder Ansible Builder is a tool that aids in the creation of Ansible Execution Environments. It does this by using the dependency information defined in various Ansible Content Collections, as well as by the user. Ansible Builder will produce a directory that acts as the build context for the container image build, which will contain the Containerfile ( Dockerfile ), along with any other files that need to be added to the image. There is no need to write a single line of Dockerfile, which makes it easy to build and use Execution Environments (EE). To build an EE, install ansible-builder from the Python Package Manager: pip3 install ansible-builder Define at least the definition file for the Execution Environment and other files, depending on your use-case. EE definition file Collection Dependencies Python Dependencies Cross-Platform requirements execution-environment.yml --- version : 1 build_arg_defaults : EE_BASE_IMAGE : 'quay.io/ansible/ansible-runner:latest' ansible_config : 'ansible.cfg' dependencies : galaxy : requirements.yml python : requirements.txt system : bindep.txt additional_build_steps : prepend : | RUN pip3 install --upgrade pip setuptools requirements.yml --- collections : - redhat.openshift requirements.txt awxkit>=13.0.0 boto>=2.49.0 botocore>=1.12.249 boto3>=1.9.249 openshift>=0.6.2 requests-oauthlib bindep.txt If there are RPMS necessary, put them here. subversion [platform:rpm] subversion [platform:dpkg] For more information, go to the Ansible Builder Documenction To build the EE, run this command (assuming you have Docker installed, by default Podman is used): ansible-builder build --tag = demo/openshift-ee --container-runtime = docker The resulting container images can be viewed with the docker images command: $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE demo/openshift-ee latest 2ea9d5d7b185 10 seconds ago 1 .14GB Ansible Runner Using the EE requires a binary which can make use of the Container images, it is not possible to run them with the ansible-playbook binary. You have to use (and install) either the ansible-navigator or the ansible-runner binary. pip3 install ansible-runner To use the Ansible from the container image, e.g. run this command which executes an ad hoc command ( setup module) against localhost: ansible-runner run --container-image demo/openshift-ee /tmp -m setup --hosts localhost Most parameters should be self-explanatory: run - Run ansible-runner in the foreground --container-image demo/openshift - Container image to use when running an ansible task /tmp - base directory containing the ansible-runner metadata (project, inventory, env, etc) -m setup - Module to execute --hosts localhost - set of hosts to execute against (here only localhost) The output looks like expected: $ ansible-runner run --container-image demo/openshift-ee /tmp -m setup --hosts localhost [ WARNING ] : No inventory was parsed, only implicit localhost is available localhost | SUCCESS = > { \"ansible_facts\" : { \"ansible_all_ipv4_addresses\" : [ \"192.168.178.114\" , \"172.17.0.1\" ] , \"ansible_all_ipv6_addresses\" : [ \"2001:9e8:4a14:2401:a00:27ff:febf:4207\" , \"fe80::a00:27ff:febf:4207\" , \"fe80::42:9eff:fef9:df59\" ] , \"ansible_apparmor\" : { \"status\" : \"enabled\" } , \"ansible_architecture\" : \"x86_64\" , \"ansible_bios_date\" : \"12/01/2006\" , \"ansible_bios_vendor\" : \"innotek GmbH\" , \"ansible_bios_version\" : \"VirtualBox\" , \"ansible_board_asset_tag\" : \"NA\" , \"ansible_board_name\" : \"VirtualBox\" , \"ansible_board_serial\" : \"NA\" , \"ansible_board_vendor\" : \"Oracle Corporation\" , ... Ansible Navigator The ansible-navigator is text-based user interface (TUI) for the Red Hat Ansible Automation Platform. It is a command based tool for creating, reviewing, and troubleshooting Ansible content, including inventories, playbooks, and collections. The Navigator also makes use of the Execution Environments and provides an easier to use interface to interact with EEs.","title":"Installation"},{"location":"ansible/installation/#installation","text":"","title":"Installation"},{"location":"ansible/installation/#_1","text":"The latest version can only be obtained via the Python package manager, the ansible-core package contains the binaries and 69 standard modules. pip3 install ansible-core If more special modules are needed, the complete ansible package can be installed, this corresponds to the \"old\" installation method ( batteries included ). pip3 install ansible Tip It makes sense to install only the ansible-core package. Afterwards, install the few collections necessary for your project via ansible-galaxy . This way you have an up-to-date, lean installation without unnecessary modules and plugins. Thereby the chapter Project > Collections is to be considered. If a container runtime is available, the complete installation can also be bundled in a container image (so-called Execution Environment ).","title":""},{"location":"ansible/installation/#execution-environments","text":"Execution Environments are container images that serve as Ansible control nodes.","title":"Execution environments"},{"location":"ansible/installation/#ansible-builder","text":"Ansible Builder is a tool that aids in the creation of Ansible Execution Environments. It does this by using the dependency information defined in various Ansible Content Collections, as well as by the user. Ansible Builder will produce a directory that acts as the build context for the container image build, which will contain the Containerfile ( Dockerfile ), along with any other files that need to be added to the image. There is no need to write a single line of Dockerfile, which makes it easy to build and use Execution Environments (EE). To build an EE, install ansible-builder from the Python Package Manager: pip3 install ansible-builder Define at least the definition file for the Execution Environment and other files, depending on your use-case. EE definition file Collection Dependencies Python Dependencies Cross-Platform requirements execution-environment.yml --- version : 1 build_arg_defaults : EE_BASE_IMAGE : 'quay.io/ansible/ansible-runner:latest' ansible_config : 'ansible.cfg' dependencies : galaxy : requirements.yml python : requirements.txt system : bindep.txt additional_build_steps : prepend : | RUN pip3 install --upgrade pip setuptools requirements.yml --- collections : - redhat.openshift requirements.txt awxkit>=13.0.0 boto>=2.49.0 botocore>=1.12.249 boto3>=1.9.249 openshift>=0.6.2 requests-oauthlib bindep.txt If there are RPMS necessary, put them here. subversion [platform:rpm] subversion [platform:dpkg] For more information, go to the Ansible Builder Documenction To build the EE, run this command (assuming you have Docker installed, by default Podman is used): ansible-builder build --tag = demo/openshift-ee --container-runtime = docker The resulting container images can be viewed with the docker images command: $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE demo/openshift-ee latest 2ea9d5d7b185 10 seconds ago 1 .14GB","title":"Ansible Builder"},{"location":"ansible/installation/#ansible-runner","text":"Using the EE requires a binary which can make use of the Container images, it is not possible to run them with the ansible-playbook binary. You have to use (and install) either the ansible-navigator or the ansible-runner binary. pip3 install ansible-runner To use the Ansible from the container image, e.g. run this command which executes an ad hoc command ( setup module) against localhost: ansible-runner run --container-image demo/openshift-ee /tmp -m setup --hosts localhost Most parameters should be self-explanatory: run - Run ansible-runner in the foreground --container-image demo/openshift - Container image to use when running an ansible task /tmp - base directory containing the ansible-runner metadata (project, inventory, env, etc) -m setup - Module to execute --hosts localhost - set of hosts to execute against (here only localhost) The output looks like expected: $ ansible-runner run --container-image demo/openshift-ee /tmp -m setup --hosts localhost [ WARNING ] : No inventory was parsed, only implicit localhost is available localhost | SUCCESS = > { \"ansible_facts\" : { \"ansible_all_ipv4_addresses\" : [ \"192.168.178.114\" , \"172.17.0.1\" ] , \"ansible_all_ipv6_addresses\" : [ \"2001:9e8:4a14:2401:a00:27ff:febf:4207\" , \"fe80::a00:27ff:febf:4207\" , \"fe80::42:9eff:fef9:df59\" ] , \"ansible_apparmor\" : { \"status\" : \"enabled\" } , \"ansible_architecture\" : \"x86_64\" , \"ansible_bios_date\" : \"12/01/2006\" , \"ansible_bios_vendor\" : \"innotek GmbH\" , \"ansible_bios_version\" : \"VirtualBox\" , \"ansible_board_asset_tag\" : \"NA\" , \"ansible_board_name\" : \"VirtualBox\" , \"ansible_board_serial\" : \"NA\" , \"ansible_board_vendor\" : \"Oracle Corporation\" , ...","title":"Ansible Runner"},{"location":"ansible/installation/#ansible-navigator","text":"The ansible-navigator is text-based user interface (TUI) for the Red Hat Ansible Automation Platform. It is a command based tool for creating, reviewing, and troubleshooting Ansible content, including inventories, playbooks, and collections. The Navigator also makes use of the Execution Environments and provides an easier to use interface to interact with EEs.","title":"Ansible Navigator"},{"location":"ansible/inventory/","text":"Inventory Warning Work in Progress - More description necessary. Multiple inventory files Inventory Es werden unterschiedliche Inventories verwendet, alle Inventory-Dateien werden im Ordner inventory hinterlegt. Gruppen im Inventory werden in der folgenden Reihenfolge definiert: Parent Children Parent-Variablen Child-Variablen","title":"Inventory"},{"location":"ansible/inventory/#inventory","text":"Warning Work in Progress - More description necessary.","title":"Inventory"},{"location":"ansible/inventory/#multiple-inventory-files","text":"","title":"Multiple inventory files"},{"location":"ansible/inventory/#inventory_1","text":"Es werden unterschiedliche Inventories verwendet, alle Inventory-Dateien werden im Ordner inventory hinterlegt. Gruppen im Inventory werden in der folgenden Reihenfolge definiert: Parent Children Parent-Variablen Child-Variablen","title":"Inventory"},{"location":"ansible/playbook/","text":"Playbooks Playbooks are first thing you think of when using Ansible. This section describes some good practices. Directory structure The main playbook should have a recognizable name, e.g. referencing the projects name or scope. If you have multiple playbooks, create a new folder playbooks and store all playbooks there, except the main playbook (here called site.yml ). . \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 site.yml \u2514\u2500\u2500 playbooks \u251c\u2500\u2500 database.yml \u251c\u2500\u2500 loadbalancer.yml \u2514\u2500\u2500 webserver.yml The site.yml file contains references to the other playbooks: --- # Main playbook including all other playbooks - import_playbook : playbooks/database.yml - import_playbook : playbooks/webserver.yml - import_playbook : playbooks/loadbalancer.yml The lower-level playbooks contains actual plays : --- # playbooks/database - name : Install and configure PostgreSQL database hosts : postgres_servers roles : - postgres To be able to run the overall playbook, as well as the imported playbooks, add this parameter to your ansible.cfg , otherwise roles are not found: [defaults] roles_path = .roles Playbook definition Don't put too much logic in your playbook, put it in your roles (or even in custom modules). A playbook could contain pre_tasks , roles , tasks and post_tasks sections, try to limit your playbooks to a list of a roles . Warning Avoid using both roles and tasks sections, the latter possibly containing import_role or include_role tasks. The order of execution between roles and tasks isn\u2019t obvious, and hence mixing them should be avoided. Either you need only static importing of roles and you can use the roles section, or you need dynamic inclusion and you should use only the tasks section. Of course, for very simple cases, you can just use tasks without roles (but playbooks/projects grow quickly, refactor to roles early). Plays Avoid putting multiple plays in a playbook, if not really necessary. As every play most likely targets a different host group, create a separate playbook file for it. This way you achieve to most flexibility. # file k8s-installation.yml - name : Initialize Control-Plane Nodes hosts : kubemaster become : true roles : - k8s-control-plane - name : Install and configure Worker Nodes hosts : kubeworker become : true roles : - k8s-worker-nodes Separate the two plays into their respective playbooks files and reference them in an overall playbook file: # file k8s-control-plane-playbook.yml - name : Initialize Control-Plane Nodes hosts : kubemaster become : true roles : - k8s-control-plane # file k8s-worker-node-playbook.yml - name : Install and configure Worker Nodes hosts : kubeworker become : true roles : - k8s-worker-nodes # file k8s-installation.yml - import_playbooks : k8s-control-plane-playbook.yml - import_playbooks : k8s-worker-node-playbook.yml","title":"Playbook"},{"location":"ansible/playbook/#playbooks","text":"Playbooks are first thing you think of when using Ansible. This section describes some good practices.","title":"Playbooks"},{"location":"ansible/playbook/#directory-structure","text":"The main playbook should have a recognizable name, e.g. referencing the projects name or scope. If you have multiple playbooks, create a new folder playbooks and store all playbooks there, except the main playbook (here called site.yml ). . \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 site.yml \u2514\u2500\u2500 playbooks \u251c\u2500\u2500 database.yml \u251c\u2500\u2500 loadbalancer.yml \u2514\u2500\u2500 webserver.yml The site.yml file contains references to the other playbooks: --- # Main playbook including all other playbooks - import_playbook : playbooks/database.yml - import_playbook : playbooks/webserver.yml - import_playbook : playbooks/loadbalancer.yml The lower-level playbooks contains actual plays : --- # playbooks/database - name : Install and configure PostgreSQL database hosts : postgres_servers roles : - postgres To be able to run the overall playbook, as well as the imported playbooks, add this parameter to your ansible.cfg , otherwise roles are not found: [defaults] roles_path = .roles","title":"Directory structure"},{"location":"ansible/playbook/#playbook-definition","text":"Don't put too much logic in your playbook, put it in your roles (or even in custom modules). A playbook could contain pre_tasks , roles , tasks and post_tasks sections, try to limit your playbooks to a list of a roles . Warning Avoid using both roles and tasks sections, the latter possibly containing import_role or include_role tasks. The order of execution between roles and tasks isn\u2019t obvious, and hence mixing them should be avoided. Either you need only static importing of roles and you can use the roles section, or you need dynamic inclusion and you should use only the tasks section. Of course, for very simple cases, you can just use tasks without roles (but playbooks/projects grow quickly, refactor to roles early).","title":"Playbook definition"},{"location":"ansible/playbook/#plays","text":"Avoid putting multiple plays in a playbook, if not really necessary. As every play most likely targets a different host group, create a separate playbook file for it. This way you achieve to most flexibility. # file k8s-installation.yml - name : Initialize Control-Plane Nodes hosts : kubemaster become : true roles : - k8s-control-plane - name : Install and configure Worker Nodes hosts : kubeworker become : true roles : - k8s-worker-nodes Separate the two plays into their respective playbooks files and reference them in an overall playbook file: # file k8s-control-plane-playbook.yml - name : Initialize Control-Plane Nodes hosts : kubemaster become : true roles : - k8s-control-plane # file k8s-worker-node-playbook.yml - name : Install and configure Worker Nodes hosts : kubeworker become : true roles : - k8s-worker-nodes # file k8s-installation.yml - import_playbooks : k8s-control-plane-playbook.yml - import_playbooks : k8s-worker-node-playbook.yml","title":"Plays"},{"location":"ansible/project/","text":"Project Version Control Keep your playbooks and inventory file in git (or another version control system), and commit when you make changes to them. This way you have an audit trail describing when and why you changed the rules that are automating your infrastructure. Tip Always use version control! Ansible configuration Always use a project-specific ansible.cfg in the parent directory of your project. The following configuration can be used as a starting point: # Define inventory, no need to provide '-i' anymore. inventory = inventory/production.ini # Playbook-Output in YAML instead of JSON, needs additional collection. stdout_callback = community.general.yaml Dependencies Your project will have certain dependencies, make sure to provide a requirements.yml for necessary Ansible collections and a requirements.txt for necessary Python packages. Consider using Execution Environments where all dependencies are combined in a Container Image. Collections Always provide a requirements.yml with all collections used within your project. This makes sure that required collections can be installed, if only the ansible-core binary is installed. --- collections : - community.general - ansible.posix - name : cisco.ios version : '>=3.1.0' Install all collections from the requirements -file: ansible-galaxy collection install -r requirements.yml Python packages Always provide a requirements.txt with all Python packages need by modules used within your project. boto openshift>=0.6 PyYAML>=3.11 Install all dependencies from the requirements -file: pip3 install -r requirements.txt Directory structure . \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 hosts \u251c\u2500\u2500 k8s-install.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 requirements.yml \u2514\u2500\u2500 roles \u251c\u2500\u2500 k8s-bootstrap \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u251c\u2500\u2500 daemon.json \u2502 \u2502 \u2514\u2500\u2500 k8s.conf \u2502 \u251c\u2500\u2500 tasks \u2502 \u2502 \u251c\u2500\u2500 install-kubeadm.yml \u2502 \u2502 \u251c\u2500\u2500 main.yml \u2502 \u2502 \u2514\u2500\u2500 prerequisites.yml \u2502 \u2514\u2500\u2500 templates \u2502 \u2514\u2500\u2500 kubernetes.repo.j2 \u251c\u2500\u2500 k8s-control-plane \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u2514\u2500\u2500 kubeconfig.sh \u2502 \u2514\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 k8s-worker-nodes \u2514\u2500\u2500 tasks \u2514\u2500\u2500 main.yml Filenames Folder- and file-names consisting of multiple words are separated with hyphens (e.g. roles/grafana-deployment/tasks/grafana-installation.yml ). YAML files are saved with the extension .yml . Good Bad . \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 hosts \u251c\u2500\u2500 k8s-install.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 requirements.yml \u2514\u2500\u2500 roles \u251c\u2500\u2500 k8s-bootstrap \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u251c\u2500\u2500 daemon.json \u2502 \u2502 \u2514\u2500\u2500 k8s.conf \u2502 \u251c\u2500\u2500 tasks \u2502 \u2502 \u251c\u2500\u2500 install-kubeadm.yml \u2502 \u2502 \u251c\u2500\u2500 main.yml \u2502 \u2502 \u2514\u2500\u2500 prerequisites.yml \u2502 \u2514\u2500\u2500 templates \u2502 \u2514\u2500\u2500 kubernetes.repo.j2 \u251c\u2500\u2500 k8s-control-plane \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u2514\u2500\u2500 kubeconfig.sh \u2502 \u2514\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 k8s-worker-nodes \u2514\u2500\u2500 tasks \u2514\u2500\u2500 main.yml Playbook-name without hyphens and wrong file extension, role folders or task files inconsistent, with underscores and wrong extension. . \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 hosts \u251c\u2500\u2500 k8s-install.yaml \u251c\u2500\u2500 README.md \u2514\u2500\u2500 roles \u251c\u2500\u2500 k8s_bootstrap \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u251c\u2500\u2500 daemon.json \u2502 \u2502 \u2514\u2500\u2500 k8s.conf \u2502 \u251c\u2500\u2500 tasks \u2502 \u2502 \u251c\u2500\u2500 installKubeadm.yaml \u2502 \u2502 \u251c\u2500\u2500 main.yml \u2502 \u2502 \u2514\u2500\u2500 prerequisites.yaml \u2502 \u2514\u2500\u2500 templates \u2502 \u2514\u2500\u2500 kubernetes.repo.j2 \u251c\u2500\u2500 k8sControlPlane \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u2514\u2500\u2500 kubeconfig.sh \u2502 \u2514\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yaml \u2514\u2500\u2500 k8s_worker-nodes \u2514\u2500\u2500 tasks \u2514\u2500\u2500 main.yaml Subject to change Maybe this has to change in the future, as collection roles only allow underscores for separation. See Ansible Docs - Roles directory for more information. Also, ansible-lint checks role names to ensure they conform these requirements, which must be disabled otherwise. YAML Syntax Following a basic YAML coding style accross the whole team improves readability and reusability. Indentation Two spaces are used to indent everything, e.g. list items or dictionary keys. Good Bad Playbook: - name : Demo play hosts : database_servers roles : - common - postgres Variable-file: ntp_server_list : - 0.de.pool.ntp.org - 1.de.pool.ntp.org - 2.de.pool.ntp.org - 3.de.pool.ntp.org Playbook with roles not indented by two whitespaces. - name : Demo play hosts : database_servers roles : - common - postgres List in variable-file indented with four whitespaces: ntp_server_list : - 0.de.pool.ntp.org - 1.de.pool.ntp.org - 2.de.pool.ntp.org - 3.de.pool.ntp.org The so-called YAML \"one-line\" syntax is not used, neither for passing parameters in tasks, nor for lists or dictionaries. Good Bad - name : Install the latest version of Apache from the testing repo ansible.builtin.yum : name : httpd enablerepo : testing state : present - name : Install a list of packages ansible.builtin.yum : name : - nginx - postgresql - postgresql-server state : present Task with One-line syntax: - name : Install the latest version of Apache from the testing repo yum : name=httpd enablerepo=testing state=present List in task with One-line syntax: - name : Install a list of packages yum : name : [ 'nginx' , 'postgresql' , 'postgresql-server' ] state : present Booleans Use true and false for boolean values in playbooks. Do not use the Ansible-specific yes and no as boolean values in YAML as these are completely custom extensions used by Ansible and are not part of the YAML spec. Also, avoid the use of the Python-style True and False for boolean values. Good Bad - name : Start and enable service httpd ansible.builtin.service : name : httpd enabled : true state : started - name : Start and enable service httpd ansible.builtin.service : name : httpd enabled : yes state : started YAML 1.1 allows all variants whereas YAML 1.2 allows only true/false , you can avoid a massive migration effort for when it becomes the default. Use the | bool filter when using bare variables (expressions consisting of just one variable reference without any operator) in when conditions. Good Bad Using a variable upgrade_allowed with the default value false , task is executed when overwritten with true value. - name : Upgrade all packages, excluding kernel & foo related packages ansible.builtin.yum : name : \"*\" state : latest exclude : kernel*,foo* when : upgrade_allowed | bool - name : Upgrade all packages, excluding kernel & foo related packages ansible.builtin.yum : name : \"*\" state : latest exclude : kernel*,foo* when : upgrade_allowed Quoting Do not use quotes unless you have to, especially for short module-keyword-like strings like present , absent , etc. When using quotes, use the same type of quotes throughout your playbooks. Always use double quotes ( \" ), whenever possible. Comments Use loads of comments! Well, the name parameter should desribe your task in detail, but if your task uses multiple filters or regexes, comments should be used for further explanation. Commented code is generally to be avoided. Playbooks or task files are not committed, if they contain commented out code. Bad Why is the second task commented? Is it not necessary anymore? Does it not work as expected? - name : Change port to {{ grafana_port }} community.general.ini_file : path : /etc/grafana/grafana.ini section : server option : http_port value : \"{{ grafana_port }}\" become : true notify : restart grafana # - name: Change theme to {{ grafana_theme }} # ansible.builtin.lineinfile: # path: /etc/grafana/grafana.ini # regexp: '.*default_theme =' # line: \"default_theme = {{ grafana_theme }}\" # become: yes # notify: restart grafana Comment commented tasks If you really have to comment the whole task, add a description why, when and by whom it was commented.","title":"Project"},{"location":"ansible/project/#project","text":"","title":"Project"},{"location":"ansible/project/#version-control","text":"Keep your playbooks and inventory file in git (or another version control system), and commit when you make changes to them. This way you have an audit trail describing when and why you changed the rules that are automating your infrastructure. Tip Always use version control!","title":"Version Control"},{"location":"ansible/project/#ansible-configuration","text":"Always use a project-specific ansible.cfg in the parent directory of your project. The following configuration can be used as a starting point: # Define inventory, no need to provide '-i' anymore. inventory = inventory/production.ini # Playbook-Output in YAML instead of JSON, needs additional collection. stdout_callback = community.general.yaml","title":"Ansible configuration"},{"location":"ansible/project/#dependencies","text":"Your project will have certain dependencies, make sure to provide a requirements.yml for necessary Ansible collections and a requirements.txt for necessary Python packages. Consider using Execution Environments where all dependencies are combined in a Container Image.","title":"Dependencies"},{"location":"ansible/project/#collections","text":"Always provide a requirements.yml with all collections used within your project. This makes sure that required collections can be installed, if only the ansible-core binary is installed. --- collections : - community.general - ansible.posix - name : cisco.ios version : '>=3.1.0' Install all collections from the requirements -file: ansible-galaxy collection install -r requirements.yml","title":"Collections"},{"location":"ansible/project/#python-packages","text":"Always provide a requirements.txt with all Python packages need by modules used within your project. boto openshift>=0.6 PyYAML>=3.11 Install all dependencies from the requirements -file: pip3 install -r requirements.txt","title":"Python packages"},{"location":"ansible/project/#directory-structure","text":". \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 hosts \u251c\u2500\u2500 k8s-install.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 requirements.yml \u2514\u2500\u2500 roles \u251c\u2500\u2500 k8s-bootstrap \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u251c\u2500\u2500 daemon.json \u2502 \u2502 \u2514\u2500\u2500 k8s.conf \u2502 \u251c\u2500\u2500 tasks \u2502 \u2502 \u251c\u2500\u2500 install-kubeadm.yml \u2502 \u2502 \u251c\u2500\u2500 main.yml \u2502 \u2502 \u2514\u2500\u2500 prerequisites.yml \u2502 \u2514\u2500\u2500 templates \u2502 \u2514\u2500\u2500 kubernetes.repo.j2 \u251c\u2500\u2500 k8s-control-plane \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u2514\u2500\u2500 kubeconfig.sh \u2502 \u2514\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 k8s-worker-nodes \u2514\u2500\u2500 tasks \u2514\u2500\u2500 main.yml","title":"Directory structure"},{"location":"ansible/project/#filenames","text":"Folder- and file-names consisting of multiple words are separated with hyphens (e.g. roles/grafana-deployment/tasks/grafana-installation.yml ). YAML files are saved with the extension .yml . Good Bad . \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 hosts \u251c\u2500\u2500 k8s-install.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 requirements.yml \u2514\u2500\u2500 roles \u251c\u2500\u2500 k8s-bootstrap \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u251c\u2500\u2500 daemon.json \u2502 \u2502 \u2514\u2500\u2500 k8s.conf \u2502 \u251c\u2500\u2500 tasks \u2502 \u2502 \u251c\u2500\u2500 install-kubeadm.yml \u2502 \u2502 \u251c\u2500\u2500 main.yml \u2502 \u2502 \u2514\u2500\u2500 prerequisites.yml \u2502 \u2514\u2500\u2500 templates \u2502 \u2514\u2500\u2500 kubernetes.repo.j2 \u251c\u2500\u2500 k8s-control-plane \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u2514\u2500\u2500 kubeconfig.sh \u2502 \u2514\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 k8s-worker-nodes \u2514\u2500\u2500 tasks \u2514\u2500\u2500 main.yml Playbook-name without hyphens and wrong file extension, role folders or task files inconsistent, with underscores and wrong extension. . \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 hosts \u251c\u2500\u2500 k8s-install.yaml \u251c\u2500\u2500 README.md \u2514\u2500\u2500 roles \u251c\u2500\u2500 k8s_bootstrap \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u251c\u2500\u2500 daemon.json \u2502 \u2502 \u2514\u2500\u2500 k8s.conf \u2502 \u251c\u2500\u2500 tasks \u2502 \u2502 \u251c\u2500\u2500 installKubeadm.yaml \u2502 \u2502 \u251c\u2500\u2500 main.yml \u2502 \u2502 \u2514\u2500\u2500 prerequisites.yaml \u2502 \u2514\u2500\u2500 templates \u2502 \u2514\u2500\u2500 kubernetes.repo.j2 \u251c\u2500\u2500 k8sControlPlane \u2502 \u251c\u2500\u2500 files \u2502 \u2502 \u2514\u2500\u2500 kubeconfig.sh \u2502 \u2514\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yaml \u2514\u2500\u2500 k8s_worker-nodes \u2514\u2500\u2500 tasks \u2514\u2500\u2500 main.yaml Subject to change Maybe this has to change in the future, as collection roles only allow underscores for separation. See Ansible Docs - Roles directory for more information. Also, ansible-lint checks role names to ensure they conform these requirements, which must be disabled otherwise.","title":"Filenames"},{"location":"ansible/project/#yaml-syntax","text":"Following a basic YAML coding style accross the whole team improves readability and reusability.","title":"YAML Syntax"},{"location":"ansible/project/#indentation","text":"Two spaces are used to indent everything, e.g. list items or dictionary keys. Good Bad Playbook: - name : Demo play hosts : database_servers roles : - common - postgres Variable-file: ntp_server_list : - 0.de.pool.ntp.org - 1.de.pool.ntp.org - 2.de.pool.ntp.org - 3.de.pool.ntp.org Playbook with roles not indented by two whitespaces. - name : Demo play hosts : database_servers roles : - common - postgres List in variable-file indented with four whitespaces: ntp_server_list : - 0.de.pool.ntp.org - 1.de.pool.ntp.org - 2.de.pool.ntp.org - 3.de.pool.ntp.org The so-called YAML \"one-line\" syntax is not used, neither for passing parameters in tasks, nor for lists or dictionaries. Good Bad - name : Install the latest version of Apache from the testing repo ansible.builtin.yum : name : httpd enablerepo : testing state : present - name : Install a list of packages ansible.builtin.yum : name : - nginx - postgresql - postgresql-server state : present Task with One-line syntax: - name : Install the latest version of Apache from the testing repo yum : name=httpd enablerepo=testing state=present List in task with One-line syntax: - name : Install a list of packages yum : name : [ 'nginx' , 'postgresql' , 'postgresql-server' ] state : present","title":"Indentation"},{"location":"ansible/project/#booleans","text":"Use true and false for boolean values in playbooks. Do not use the Ansible-specific yes and no as boolean values in YAML as these are completely custom extensions used by Ansible and are not part of the YAML spec. Also, avoid the use of the Python-style True and False for boolean values. Good Bad - name : Start and enable service httpd ansible.builtin.service : name : httpd enabled : true state : started - name : Start and enable service httpd ansible.builtin.service : name : httpd enabled : yes state : started YAML 1.1 allows all variants whereas YAML 1.2 allows only true/false , you can avoid a massive migration effort for when it becomes the default. Use the | bool filter when using bare variables (expressions consisting of just one variable reference without any operator) in when conditions. Good Bad Using a variable upgrade_allowed with the default value false , task is executed when overwritten with true value. - name : Upgrade all packages, excluding kernel & foo related packages ansible.builtin.yum : name : \"*\" state : latest exclude : kernel*,foo* when : upgrade_allowed | bool - name : Upgrade all packages, excluding kernel & foo related packages ansible.builtin.yum : name : \"*\" state : latest exclude : kernel*,foo* when : upgrade_allowed","title":"Booleans"},{"location":"ansible/project/#quoting","text":"Do not use quotes unless you have to, especially for short module-keyword-like strings like present , absent , etc. When using quotes, use the same type of quotes throughout your playbooks. Always use double quotes ( \" ), whenever possible.","title":"Quoting"},{"location":"ansible/project/#comments","text":"Use loads of comments! Well, the name parameter should desribe your task in detail, but if your task uses multiple filters or regexes, comments should be used for further explanation. Commented code is generally to be avoided. Playbooks or task files are not committed, if they contain commented out code. Bad Why is the second task commented? Is it not necessary anymore? Does it not work as expected? - name : Change port to {{ grafana_port }} community.general.ini_file : path : /etc/grafana/grafana.ini section : server option : http_port value : \"{{ grafana_port }}\" become : true notify : restart grafana # - name: Change theme to {{ grafana_theme }} # ansible.builtin.lineinfile: # path: /etc/grafana/grafana.ini # regexp: '.*default_theme =' # line: \"default_theme = {{ grafana_theme }}\" # become: yes # notify: restart grafana Comment commented tasks If you really have to comment the whole task, add a description why, when and by whom it was commented.","title":"Comments"},{"location":"ansible/roles/","text":"Roles New playbook functionality is always added in a role. Roles should only serve a defined purpose that is unambiguous by the role name. The role name should be short and unique. It is separated with hyphens, if it consists of several words. Readme Every role must have a role-specific README.md describing scope and focus of the role. Use the following example: # Role name/title Brief description of the role, what it does and what not. ## Requirements Technical requirements, e.g. necessary packages/rpms, own modules or plugins. ## Role Variables The role uses the following variables: | Variable Name | Type | Default Value | Description | | ------------- | ------- | ------------- | ---------------------- | | example | Boolean | false | Brief description | ## Dependencies This role expects to run **after** the following roles: * repository * networking * common * software ## Tags The role can be executed with the following tags: * install * configure * service ## Example Playbook Use the role in a playbook like this (after running plays/roles from dependencies section): ```yaml - name : Execute role hosts : example_servers become : true roles : - example-role ``` ## Authors Tim Gr\u00fctzmacher - <tim.gruetzmacher@computacenter.com> Role structure Role skeleton The ansible-galaxy utility can be used to create the role skeleton with the following command: ansible-galaxy role init roles/demo This would create the following directory: roles/demo/ \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 templates \u251c\u2500\u2500 tests \u2502 \u251c\u2500\u2500 inventory \u2502 \u2514\u2500\u2500 test.yml \u251c\u2500\u2500 .travis.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 main.yml At least the folders (and content) tests (a sample inventory and playbook for testing, we will use a different testing method) and vars (variable definitions, not used according to this Best Practice Guide, because we use only group_vars , host_vars and defaults ) are not necessary. Also the .travis.yml (a CI/CD solution) definition is not useful. Tip Use a custom role skeleton which is used by ansible-galaxy ! Consider the following role skeleton, note the missing vars and test folder and the newly added Molecule folder . roles/role-skeleton/ \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 molecule \u2502 \u2514\u2500\u2500 default \u2502 \u251c\u2500\u2500 converge.yml \u2502 \u2514\u2500\u2500 molecule.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 templates You need to define the following parameter in your custom ansible.cfg : [galaxy] role_skeleton = roles/role-skeleton Success Afterwards, initializing a new role with ansible-galaxy role init creates a role structure with exactly the content you need!","title":"Roles"},{"location":"ansible/roles/#roles","text":"New playbook functionality is always added in a role. Roles should only serve a defined purpose that is unambiguous by the role name. The role name should be short and unique. It is separated with hyphens, if it consists of several words.","title":"Roles"},{"location":"ansible/roles/#readme","text":"Every role must have a role-specific README.md describing scope and focus of the role. Use the following example: # Role name/title Brief description of the role, what it does and what not. ## Requirements Technical requirements, e.g. necessary packages/rpms, own modules or plugins. ## Role Variables The role uses the following variables: | Variable Name | Type | Default Value | Description | | ------------- | ------- | ------------- | ---------------------- | | example | Boolean | false | Brief description | ## Dependencies This role expects to run **after** the following roles: * repository * networking * common * software ## Tags The role can be executed with the following tags: * install * configure * service ## Example Playbook Use the role in a playbook like this (after running plays/roles from dependencies section): ```yaml - name : Execute role hosts : example_servers become : true roles : - example-role ``` ## Authors Tim Gr\u00fctzmacher - <tim.gruetzmacher@computacenter.com>","title":"Readme"},{"location":"ansible/roles/#role-structure","text":"","title":"Role structure"},{"location":"ansible/roles/#role-skeleton","text":"The ansible-galaxy utility can be used to create the role skeleton with the following command: ansible-galaxy role init roles/demo This would create the following directory: roles/demo/ \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 templates \u251c\u2500\u2500 tests \u2502 \u251c\u2500\u2500 inventory \u2502 \u2514\u2500\u2500 test.yml \u251c\u2500\u2500 .travis.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 main.yml At least the folders (and content) tests (a sample inventory and playbook for testing, we will use a different testing method) and vars (variable definitions, not used according to this Best Practice Guide, because we use only group_vars , host_vars and defaults ) are not necessary. Also the .travis.yml (a CI/CD solution) definition is not useful. Tip Use a custom role skeleton which is used by ansible-galaxy ! Consider the following role skeleton, note the missing vars and test folder and the newly added Molecule folder . roles/role-skeleton/ \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 molecule \u2502 \u2514\u2500\u2500 default \u2502 \u251c\u2500\u2500 converge.yml \u2502 \u2514\u2500\u2500 molecule.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 templates You need to define the following parameter in your custom ansible.cfg : [galaxy] role_skeleton = roles/role-skeleton Success Afterwards, initializing a new role with ansible-galaxy role init creates a role structure with exactly the content you need!","title":"Role skeleton"},{"location":"ansible/tasks/","text":"Tasks Tasks should always be inside of a role. Do not use tasks in a play directly. Logically related tasks are to be separated into individual files, the main.yml of a role only imports other task files. . \u2514\u2500\u2500 roles \u2514\u2500\u2500 k8s-bootstrap \u2514\u2500\u2500 tasks \u251c\u2500\u2500 install-kubeadm.yml \u251c\u2500\u2500 main.yml \u2514\u2500\u2500 prerequisites.yml The file name of a task file should describe the content. --- # tasks/main.yml - import_tasks : prerequisites.yml - import_tasks : install-kubeadm.yml Tags Don't use too many tags, it gets confusing very quickly. Tags should only be allowed for imported task files within the main.yml of a role. Tags at the task level in sub-task files should be avoided. --- # tasks/main.yml - import_tasks : installation.yml tags : - install - import_tasks : configuration.yml tags : - configure Try to use the same tags across your roles, this way you would be able to run only e.g. installation tasks from multiple roles. Idempotence Each task must be idempotent, if non-idempotent modules are used ( command , shell , raw ) these tasks must be developed via appropriate parameters or conditions to an idempotent mode of operation. Tip In general, the use of non-idempotent modules should be reduced to a necessary minimum. command vs. shell module In most of the use cases, both shell and command modules perform the same job. However, there are few main differences between these two modules. The command module uses the Python interpreter on the target node (as all other modules), the shell module runs a real shell on the target (pipeing and redirections are available, as well as access to environment variables). Tip Always try to use the command module over the shell module, if you do not explicitly need shell functionality. Parsing shell metacharacters can lead to unexpected commands being executed if quoting is not done correctly so it is more secure to use the command module when possible. To sanitize any variables passed to the shell module, you should use {{ var | quote }} instead of just {{ var }} to make sure they do not include evil things like semicolons. creates and removes Check mode is supported for non-idempotent modules when passing creates or removes . If running in check mode and either of these are specified, the module will check for the existence of the file and report the correct changed status. If these are not supplied, the task will be skipped. Warning Work in Progress - More description necessary. failed_when and changed_when Good Bad - name : Install webserver package ansible.builtin.yum : name : httpd state : present This task never reports a changed state or fails when an error occurs. - name : Install webserver package shell : sudo yum install http changed_when : false failed_when : false Naming tasks It is possible to leave off the name for a given task, though it is recommended to provide a description about why something is being done instead. This description is shown when the playbook is run. Write task names in the imperative (e.g. \"Ensure service is running\" ), this communicates the action of the task. Start with a capital letter. Good Bad - name : Install webserver package ansible.builtin.yum : name : httpd state : present - yum : name : httpd state : present Using name parameter, but not starting with capital letter, nor desrcibing the task properly. - name : install package yum : name : httpd state : present Prefix task names in sub-task files It is a common practice to have tasks/main.yml file including other tasks files, which we\u2019ll call sub-tasks files. Make sure that the tasks' names in these sub-tasks files are prefixed with a shortcut reminding of the sub-tasks file\u2019s name. Especially in a complex role with multiple (sub-)tasks file, it becomes difficult to understand which task belongs to which file. - name : kubeadm-setup | Install kubeadm, kubelet and kubectl ansible.builtin.yum : name : - kubelet - kubeadm - kubectl state : present The log output will then look like this: ... TASK [ k8s-bootstrap: kubeadm-setup | Install kubeadm, kubelet and kubectl ] ********** changed: [ kubemaster ] ... FQCN Use the full qualified collection names (FQCN) for modules, they are supported since Version 2.9 and ensures your tasks are set for the future. Good Bad - name : Install webserver package ansible.builtin.yum : name : httpd state : present - yum : name : httpd state : present In Ansible 2.10, many plugins and modules have migrated to Collections on Ansible Galaxy. Your playbooks should continue to work without any changes. Using the FQCN in your playbooks ensures the explicit and authoritative indicator of which collection to use as some collections may contain duplicate module names. Permissions When using modules like copy or template you can (and should) set permissions for the files/templates deployed with the mode parameter. For those used to /usr/bin/chmod , remember that modes are actually octal numbers. You must either add a leading zero so that Ansible\u2019s YAML parser knows it is an octal number (like 0644 or 01777 ) or quote it (like \"644\" or \"1777\" ) so Ansible receives a string and can do its own conversion from string into number. Warning Giving Ansible a number without following one of these rules will end up with a decimal number which will have unexpected results. Good Bad - name : Copy index.html template ansible.builtin.template : src : welcome.html dest : /var/www/html/index.html mode : 0644 owner : apache group : apache become : true Missing leading zero: - name : copy index template : src : welcome.html dest : /var/www/html/index.html mode : 644 owner : apache group : apache become : true This leads to these permissions! [ root@demo / ] # ll /var/www/html/ total 68 --w----r-T 1 apache apache 67691 Nov 18 14 :30 index.html State definition The state parameter is optional to a lot of modules. Whether state: present or state: absent , it\u2019s always best to leave that parameter in your playbooks to make it clear, especially as some modules support additional states. Conditionals If the when: condition results in a line that is very long, and is an and expression, then break it into a list of conditions. Good Bad - name : Set motd message for k8s worker node ansible.builtin.copy : content : \"This host is used as k8s worker.\\n\" dest : /etc/motd when : - inventory_hostname in groups['kubeworker'] - kubeadm_join_result.rc == 0 - name : Set motd message for k8s worker node copy : content : \"This host is used as k8s worker.\\n\" dest : /etc/motd when : inventory_hostname in groups['kubeworker'] and kubeadm_join_result.rc == 0 When using conditions on blocks , move the when statement to the top, below the name parameter, to improve readability. Good Bad - name : Install, configure, and start Apache when : ansible_facts['distribution'] == 'CentOS' block : - name : Install httpd and memcached ansible.builtin.yum : name : - httpd - memcached state : present - name : Apply the foo config template ansible.builtin.template : src : templates/src.j2 dest : /etc/foo.conf - name : Start service bar and enable it ansible.builtin.service : name : bar state : started enabled : true - name : Install, configure, and start Apache block : - name : Install httpd and memcached ansible.builtin.yum : name : - httpd - memcached state : present - name : Apply the foo config template ansible.builtin.template : src : templates/src.j2 dest : /etc/foo.conf - name : Start service bar and enable it ansible.builtin.service : name : bar state : started enabled : True when : ansible_facts['distribution'] == 'CentOS' Avoid the use of when: foo_result is changed whenever possible. Use handlers, and, if necessary, handler chains to achieve this same result. Loops Warning Work in Progress - More description necessary. Converting from with_<lookup> to loop is described with a Migration Guide in the Ansible documentation Limit loop output When looping over complex data structures, the console output of your task can be enormous. To limit the displayed output, use the label directive with loop_control . For example, this tasks creates users with multiple parameters in a loop: - name : Create local users user : name : \"{{ item.name }}\" groups : \"{{ item.groups }}\" append : \"{{ item.append }}\" comment : \"{{ item.comment }}\" generate_ssh_key : true password_expire_max : \"{{ item.password_expire_max }}\" loop : \"{{ user_list }}\" loop_control : label : \"{{ item.name }}\" # (1)! Content of variable user_list : user_list : - name : tgruetz groups : admins,docker append : false comment : Tim Gr\u00fctzmacher shell : /bin/bash password_expire_max : 180 - name : joschmi groups : developers,docker append : true comment : Jonathan Schmidt shell : /bin/zsh password_expire_max : 90 - name : mfrink groups : developers append : true comment : Mathias Frink shell : /bin/bash password_expire_max : 90 Running the playbook results in the following task output, only the content of the name parameter is shown instead of all key-value pairs in the list item. Good Bad TASK [ common : Create local users ] ********************************************* Friday 18 November 2022 12 :18:01 +0100 ( 0 :00:01.955 ) 0 :00:03.933 ******* changed: [ demo ] = > ( item = tgruetz ) changed: [ demo ] = > ( item = joschmi ) changed: [ demo ] = > ( item = mfrink ) Not using the label in the loop_control dictionary results in a very long output: TASK [ common : Create local users ] ********************************************* Friday 18 November 2022 12 :22:40 +0100 ( 0 :00:01.512 ) 0 :00:03.609 ******* changed: [ demo ] = > ( item ={ 'name' : 'tgruetz' , 'groups' : 'admins,docker' , 'append' : False, 'comment' : 'Tim Gr\u00fctzmacher' , 'shell' : '/bin/bash' , 'password_expire_max' : 90 }) changed: [ demo ] = > ( item ={ 'name' : 'joschmi' , 'groups' : 'developers,docker' , 'append' : True, 'comment' : 'Jonathan Schmidt' , 'shell' : '/bin/zsh' , 'password_expire_max' : 90 }) changed: [ demo ] = > ( item ={ 'name' : 'mfrink' , 'groups' : 'developers' , 'append' : True, 'comment' : 'Mathias Frink' , 'shell' : '/bin/bash' , 'password_expire_max' : 90 }) Filter Warning Work in Progress - More description necessary.","title":"Tasks"},{"location":"ansible/tasks/#tasks","text":"Tasks should always be inside of a role. Do not use tasks in a play directly. Logically related tasks are to be separated into individual files, the main.yml of a role only imports other task files. . \u2514\u2500\u2500 roles \u2514\u2500\u2500 k8s-bootstrap \u2514\u2500\u2500 tasks \u251c\u2500\u2500 install-kubeadm.yml \u251c\u2500\u2500 main.yml \u2514\u2500\u2500 prerequisites.yml The file name of a task file should describe the content. --- # tasks/main.yml - import_tasks : prerequisites.yml - import_tasks : install-kubeadm.yml","title":"Tasks"},{"location":"ansible/tasks/#tags","text":"Don't use too many tags, it gets confusing very quickly. Tags should only be allowed for imported task files within the main.yml of a role. Tags at the task level in sub-task files should be avoided. --- # tasks/main.yml - import_tasks : installation.yml tags : - install - import_tasks : configuration.yml tags : - configure Try to use the same tags across your roles, this way you would be able to run only e.g. installation tasks from multiple roles.","title":"Tags"},{"location":"ansible/tasks/#idempotence","text":"Each task must be idempotent, if non-idempotent modules are used ( command , shell , raw ) these tasks must be developed via appropriate parameters or conditions to an idempotent mode of operation. Tip In general, the use of non-idempotent modules should be reduced to a necessary minimum.","title":"Idempotence"},{"location":"ansible/tasks/#command-vs-shell-module","text":"In most of the use cases, both shell and command modules perform the same job. However, there are few main differences between these two modules. The command module uses the Python interpreter on the target node (as all other modules), the shell module runs a real shell on the target (pipeing and redirections are available, as well as access to environment variables). Tip Always try to use the command module over the shell module, if you do not explicitly need shell functionality. Parsing shell metacharacters can lead to unexpected commands being executed if quoting is not done correctly so it is more secure to use the command module when possible. To sanitize any variables passed to the shell module, you should use {{ var | quote }} instead of just {{ var }} to make sure they do not include evil things like semicolons.","title":"command vs. shell module"},{"location":"ansible/tasks/#creates-and-removes","text":"Check mode is supported for non-idempotent modules when passing creates or removes . If running in check mode and either of these are specified, the module will check for the existence of the file and report the correct changed status. If these are not supplied, the task will be skipped. Warning Work in Progress - More description necessary.","title":"creates and removes"},{"location":"ansible/tasks/#failed_when-and-changed_when","text":"Good Bad - name : Install webserver package ansible.builtin.yum : name : httpd state : present This task never reports a changed state or fails when an error occurs. - name : Install webserver package shell : sudo yum install http changed_when : false failed_when : false","title":"failed_when and changed_when"},{"location":"ansible/tasks/#naming-tasks","text":"It is possible to leave off the name for a given task, though it is recommended to provide a description about why something is being done instead. This description is shown when the playbook is run. Write task names in the imperative (e.g. \"Ensure service is running\" ), this communicates the action of the task. Start with a capital letter. Good Bad - name : Install webserver package ansible.builtin.yum : name : httpd state : present - yum : name : httpd state : present Using name parameter, but not starting with capital letter, nor desrcibing the task properly. - name : install package yum : name : httpd state : present","title":"Naming tasks"},{"location":"ansible/tasks/#prefix-task-names-in-sub-task-files","text":"It is a common practice to have tasks/main.yml file including other tasks files, which we\u2019ll call sub-tasks files. Make sure that the tasks' names in these sub-tasks files are prefixed with a shortcut reminding of the sub-tasks file\u2019s name. Especially in a complex role with multiple (sub-)tasks file, it becomes difficult to understand which task belongs to which file. - name : kubeadm-setup | Install kubeadm, kubelet and kubectl ansible.builtin.yum : name : - kubelet - kubeadm - kubectl state : present The log output will then look like this: ... TASK [ k8s-bootstrap: kubeadm-setup | Install kubeadm, kubelet and kubectl ] ********** changed: [ kubemaster ] ...","title":"Prefix task names in sub-task files"},{"location":"ansible/tasks/#fqcn","text":"Use the full qualified collection names (FQCN) for modules, they are supported since Version 2.9 and ensures your tasks are set for the future. Good Bad - name : Install webserver package ansible.builtin.yum : name : httpd state : present - yum : name : httpd state : present In Ansible 2.10, many plugins and modules have migrated to Collections on Ansible Galaxy. Your playbooks should continue to work without any changes. Using the FQCN in your playbooks ensures the explicit and authoritative indicator of which collection to use as some collections may contain duplicate module names.","title":"FQCN"},{"location":"ansible/tasks/#permissions","text":"When using modules like copy or template you can (and should) set permissions for the files/templates deployed with the mode parameter. For those used to /usr/bin/chmod , remember that modes are actually octal numbers. You must either add a leading zero so that Ansible\u2019s YAML parser knows it is an octal number (like 0644 or 01777 ) or quote it (like \"644\" or \"1777\" ) so Ansible receives a string and can do its own conversion from string into number. Warning Giving Ansible a number without following one of these rules will end up with a decimal number which will have unexpected results. Good Bad - name : Copy index.html template ansible.builtin.template : src : welcome.html dest : /var/www/html/index.html mode : 0644 owner : apache group : apache become : true Missing leading zero: - name : copy index template : src : welcome.html dest : /var/www/html/index.html mode : 644 owner : apache group : apache become : true This leads to these permissions! [ root@demo / ] # ll /var/www/html/ total 68 --w----r-T 1 apache apache 67691 Nov 18 14 :30 index.html","title":"Permissions"},{"location":"ansible/tasks/#state-definition","text":"The state parameter is optional to a lot of modules. Whether state: present or state: absent , it\u2019s always best to leave that parameter in your playbooks to make it clear, especially as some modules support additional states.","title":"State definition"},{"location":"ansible/tasks/#conditionals","text":"If the when: condition results in a line that is very long, and is an and expression, then break it into a list of conditions. Good Bad - name : Set motd message for k8s worker node ansible.builtin.copy : content : \"This host is used as k8s worker.\\n\" dest : /etc/motd when : - inventory_hostname in groups['kubeworker'] - kubeadm_join_result.rc == 0 - name : Set motd message for k8s worker node copy : content : \"This host is used as k8s worker.\\n\" dest : /etc/motd when : inventory_hostname in groups['kubeworker'] and kubeadm_join_result.rc == 0 When using conditions on blocks , move the when statement to the top, below the name parameter, to improve readability. Good Bad - name : Install, configure, and start Apache when : ansible_facts['distribution'] == 'CentOS' block : - name : Install httpd and memcached ansible.builtin.yum : name : - httpd - memcached state : present - name : Apply the foo config template ansible.builtin.template : src : templates/src.j2 dest : /etc/foo.conf - name : Start service bar and enable it ansible.builtin.service : name : bar state : started enabled : true - name : Install, configure, and start Apache block : - name : Install httpd and memcached ansible.builtin.yum : name : - httpd - memcached state : present - name : Apply the foo config template ansible.builtin.template : src : templates/src.j2 dest : /etc/foo.conf - name : Start service bar and enable it ansible.builtin.service : name : bar state : started enabled : True when : ansible_facts['distribution'] == 'CentOS' Avoid the use of when: foo_result is changed whenever possible. Use handlers, and, if necessary, handler chains to achieve this same result.","title":"Conditionals"},{"location":"ansible/tasks/#loops","text":"Warning Work in Progress - More description necessary. Converting from with_<lookup> to loop is described with a Migration Guide in the Ansible documentation","title":"Loops"},{"location":"ansible/tasks/#limit-loop-output","text":"When looping over complex data structures, the console output of your task can be enormous. To limit the displayed output, use the label directive with loop_control . For example, this tasks creates users with multiple parameters in a loop: - name : Create local users user : name : \"{{ item.name }}\" groups : \"{{ item.groups }}\" append : \"{{ item.append }}\" comment : \"{{ item.comment }}\" generate_ssh_key : true password_expire_max : \"{{ item.password_expire_max }}\" loop : \"{{ user_list }}\" loop_control : label : \"{{ item.name }}\" # (1)! Content of variable user_list : user_list : - name : tgruetz groups : admins,docker append : false comment : Tim Gr\u00fctzmacher shell : /bin/bash password_expire_max : 180 - name : joschmi groups : developers,docker append : true comment : Jonathan Schmidt shell : /bin/zsh password_expire_max : 90 - name : mfrink groups : developers append : true comment : Mathias Frink shell : /bin/bash password_expire_max : 90 Running the playbook results in the following task output, only the content of the name parameter is shown instead of all key-value pairs in the list item. Good Bad TASK [ common : Create local users ] ********************************************* Friday 18 November 2022 12 :18:01 +0100 ( 0 :00:01.955 ) 0 :00:03.933 ******* changed: [ demo ] = > ( item = tgruetz ) changed: [ demo ] = > ( item = joschmi ) changed: [ demo ] = > ( item = mfrink ) Not using the label in the loop_control dictionary results in a very long output: TASK [ common : Create local users ] ********************************************* Friday 18 November 2022 12 :22:40 +0100 ( 0 :00:01.512 ) 0 :00:03.609 ******* changed: [ demo ] = > ( item ={ 'name' : 'tgruetz' , 'groups' : 'admins,docker' , 'append' : False, 'comment' : 'Tim Gr\u00fctzmacher' , 'shell' : '/bin/bash' , 'password_expire_max' : 90 }) changed: [ demo ] = > ( item ={ 'name' : 'joschmi' , 'groups' : 'developers,docker' , 'append' : True, 'comment' : 'Jonathan Schmidt' , 'shell' : '/bin/zsh' , 'password_expire_max' : 90 }) changed: [ demo ] = > ( item ={ 'name' : 'mfrink' , 'groups' : 'developers' , 'append' : True, 'comment' : 'Mathias Frink' , 'shell' : '/bin/bash' , 'password_expire_max' : 90 })","title":"Limit loop output"},{"location":"ansible/tasks/#filter","text":"Warning Work in Progress - More description necessary.","title":"Filter"},{"location":"ansible/variables/","text":"Variables Where to put variables I always store all my variables at the following three locations: group_vars folder host_vars folder defaults folder in roles The defaults -folder contains only default values for all variables used by the role. Naming Variables The variable name should be self-explanatory ( as brief as possible, as detailed as necessary ), use multiple words and don't shorten things. Multiple words are separated with underscores ( _ ) List -Variables are suffixed with _list Dictionary -Variables are suffixed with _dict Boolean values are provided with lowercase true or false Good Bad download_directory : ~/.local/bin create_key : true needs_agent : false dir : ~/.local/bin create_key : yes needsAgent : no knows_oop : True Referencing variables After a variable is defined, use Jinja2 syntax to reference it. Jinja2 variables use double curly braces ( {{ and }} ). Use spaces after and before the double curly braces and the variable name. When referencing list or dictionary variables, try to use the bracket notation instead of the dot notation . Bracket notation always works and you can use variables inside the brackets. Dot notation can cause problems because some keys collide with attributes and methods of python dictionaries. Good Bad Simple variable reference: - name : Deploy configuration file ansible.builtin.template : src : foo.cfg.j2 dest : \"{{ remote_install_path }}/foo.cfg\" Bracket-notation and using variable ( interface_name ) inside: - name : Output IPv4 address of {{ interface_name }} interface ansible.builtin.debug : msg : \"{{ ansible_facts[interface_name]['ipv4']['address'] }}\" Not using whitespaces around variable name. - name : Deploy configuration file ansible.builtin.template : src : foo.cfg.j2 dest : \"{{remote_install_path}}/foo.cfg\" Not using whitespaces and using dot-notation. - name : Output IPv4 address of eth0 interface ansible.builtin.debug : msg : \"{{ansible_facts.eth0.ipv4.address}}\" Encrypted variables Tip All variables with sensitive content should be vault -encrypted. Although encrypting just the value of a single variable is possible (with ansible-vault encrypt_string ), you should avoid this. Store all sensitive variables in a single file and encrypt the whole file. For example, to store sensitive variables in group_vars , create the subdirectory for the group and within create two files named vars.yml and vault.yml . Inside of the vars.yml file, define all of the variables needed, including any sensitive ones. Next, copy all of the sensitive variables over to the vault.yml file and prefix these variables with vault_ . Adjust the variables in the vars file to point to the matching vault_ variables using Jinja2 syntax, and ensure that the vault file is vault encrypted. Good Bad --- # file: group_vars/database_servers/vars.yml username : \"{{ vault_username }}\" password : \"{{ vault_password }}\" --- # file: group_vars/database_servers/vault.yml # NOTE: THIS FILE MUST ALWAYS BE VAULT-ENCRYPTED vault_username : admin vault_password : ex4mple I can still read the credentials...? Obviously, you wouldn't be able to read the content of the file group_vars/database_servers/vault.yml , as the file would be encrypted. This only demonstrates how the variables are referencing each other. The encrypted vault.yml file looks something like this: $ANSIBLE_VAULT;1.1;AES256 30653164396132376333316665656131666165613863343330616666376264353830323234623631 6361303062336532303665643765336464656164363662370a663834313837303437323332336631 65656335643031393065333366366639653330353634303664653135653230656461666266356530 3935346533343834650a323934346666383032636562613966633136663631636435333834393261 36363833373439333735653262306331333062383630623432633134386138656636343137333439 61633965323066633433373137383330366466366332626334633234376231393330363335353436 62383866616232323132376366326161386561666238623731323835633237373036636561666165 36363838313737656232376365346136633934373861326130636531616438643036656137373762 39616234353135613063393536306536303065653231306166306432623232356465613063336439 34636232346334386464313935356537323832666436393336366536626463326631653137313639 36353532623161653266666436646135396632656133623762643131323439613534643430636333 31386635613238613233 # file: group_vars/database_servers.yml username : admin password : ex4mple Defining variables this way makes sure that you can still find them with grep . Encrypting files can be done with this command: ansible-vault encrypt group_vars/database_servers/vault.yml Once a variable file is encrypted, it should not be decrypted again (because it may get commited unencrypted). View or edit the file like this: ansible-vault view group_vars/database_servers/vault.yml ansible-vault edit group_vars/database_servers/vault.yml","title":"Variables"},{"location":"ansible/variables/#variables","text":"","title":"Variables"},{"location":"ansible/variables/#where-to-put-variables","text":"I always store all my variables at the following three locations: group_vars folder host_vars folder defaults folder in roles The defaults -folder contains only default values for all variables used by the role.","title":"Where to put variables"},{"location":"ansible/variables/#naming-variables","text":"The variable name should be self-explanatory ( as brief as possible, as detailed as necessary ), use multiple words and don't shorten things. Multiple words are separated with underscores ( _ ) List -Variables are suffixed with _list Dictionary -Variables are suffixed with _dict Boolean values are provided with lowercase true or false Good Bad download_directory : ~/.local/bin create_key : true needs_agent : false dir : ~/.local/bin create_key : yes needsAgent : no knows_oop : True","title":"Naming Variables"},{"location":"ansible/variables/#referencing-variables","text":"After a variable is defined, use Jinja2 syntax to reference it. Jinja2 variables use double curly braces ( {{ and }} ). Use spaces after and before the double curly braces and the variable name. When referencing list or dictionary variables, try to use the bracket notation instead of the dot notation . Bracket notation always works and you can use variables inside the brackets. Dot notation can cause problems because some keys collide with attributes and methods of python dictionaries. Good Bad Simple variable reference: - name : Deploy configuration file ansible.builtin.template : src : foo.cfg.j2 dest : \"{{ remote_install_path }}/foo.cfg\" Bracket-notation and using variable ( interface_name ) inside: - name : Output IPv4 address of {{ interface_name }} interface ansible.builtin.debug : msg : \"{{ ansible_facts[interface_name]['ipv4']['address'] }}\" Not using whitespaces around variable name. - name : Deploy configuration file ansible.builtin.template : src : foo.cfg.j2 dest : \"{{remote_install_path}}/foo.cfg\" Not using whitespaces and using dot-notation. - name : Output IPv4 address of eth0 interface ansible.builtin.debug : msg : \"{{ansible_facts.eth0.ipv4.address}}\"","title":"Referencing variables"},{"location":"ansible/variables/#encrypted-variables","text":"Tip All variables with sensitive content should be vault -encrypted. Although encrypting just the value of a single variable is possible (with ansible-vault encrypt_string ), you should avoid this. Store all sensitive variables in a single file and encrypt the whole file. For example, to store sensitive variables in group_vars , create the subdirectory for the group and within create two files named vars.yml and vault.yml . Inside of the vars.yml file, define all of the variables needed, including any sensitive ones. Next, copy all of the sensitive variables over to the vault.yml file and prefix these variables with vault_ . Adjust the variables in the vars file to point to the matching vault_ variables using Jinja2 syntax, and ensure that the vault file is vault encrypted. Good Bad --- # file: group_vars/database_servers/vars.yml username : \"{{ vault_username }}\" password : \"{{ vault_password }}\" --- # file: group_vars/database_servers/vault.yml # NOTE: THIS FILE MUST ALWAYS BE VAULT-ENCRYPTED vault_username : admin vault_password : ex4mple I can still read the credentials...? Obviously, you wouldn't be able to read the content of the file group_vars/database_servers/vault.yml , as the file would be encrypted. This only demonstrates how the variables are referencing each other. The encrypted vault.yml file looks something like this: $ANSIBLE_VAULT;1.1;AES256 30653164396132376333316665656131666165613863343330616666376264353830323234623631 6361303062336532303665643765336464656164363662370a663834313837303437323332336631 65656335643031393065333366366639653330353634303664653135653230656461666266356530 3935346533343834650a323934346666383032636562613966633136663631636435333834393261 36363833373439333735653262306331333062383630623432633134386138656636343137333439 61633965323066633433373137383330366466366332626334633234376231393330363335353436 62383866616232323132376366326161386561666238623731323835633237373036636561666165 36363838313737656232376365346136633934373861326130636531616438643036656137373762 39616234353135613063393536306536303065653231306166306432623232356465613063336439 34636232346334386464313935356537323832666436393336366536626463326631653137313639 36353532623161653266666436646135396632656133623762643131323439613534643430636333 31386635613238613233 # file: group_vars/database_servers.yml username : admin password : ex4mple Defining variables this way makes sure that you can still find them with grep . Encrypting files can be done with this command: ansible-vault encrypt group_vars/database_servers/vault.yml Once a variable file is encrypted, it should not be decrypted again (because it may get commited unencrypted). View or edit the file like this: ansible-vault view group_vars/database_servers/vault.yml ansible-vault edit group_vars/database_servers/vault.yml","title":"Encrypted variables"},{"location":"development/","text":"Development This topic is split into three main sections, each section covers a different additional tool to consider when developing your Ansible content. Linting - Installation and usage of the community backed Ansible Best Practice checker Testing - How to test your Ansible content during development Extending - Create your own custom modules and plugins Tools Each section above make use of an additional tool to support you during your Ansible content development, in most cases the standalone installation, as well as a custom container-based installation and usage method is described. The Ansible community provides a Container image bundling all the tools described in the sections above. docker pull quay.io/ansible/creator-ee For example you could output the version of the installed tools like this: docker run --rm quay.io/ansible/creator-ee ansible-lint --version docker run --rm quay.io/ansible/creator-ee molecule --version Take a look into the respective sections for more information and additional usage instructions.","title":"Development"},{"location":"development/#development","text":"This topic is split into three main sections, each section covers a different additional tool to consider when developing your Ansible content. Linting - Installation and usage of the community backed Ansible Best Practice checker Testing - How to test your Ansible content during development Extending - Create your own custom modules and plugins","title":"Development"},{"location":"development/#tools","text":"Each section above make use of an additional tool to support you during your Ansible content development, in most cases the standalone installation, as well as a custom container-based installation and usage method is described. The Ansible community provides a Container image bundling all the tools described in the sections above. docker pull quay.io/ansible/creator-ee For example you could output the version of the installed tools like this: docker run --rm quay.io/ansible/creator-ee ansible-lint --version docker run --rm quay.io/ansible/creator-ee molecule --version Take a look into the respective sections for more information and additional usage instructions.","title":"Tools"},{"location":"development/extending/","text":"Extending Ansible Warning Work in Progress - More description necessary.","title":"Extending"},{"location":"development/extending/#extending-ansible","text":"Warning Work in Progress - More description necessary.","title":"Extending Ansible"},{"location":"development/linting/","text":"Linting Ansible Lint is a best-practice checker for Ansible, maintained by the Ansible community. Installation Ansible Lint is installed through the Python packet manager: Note Ansible Lint always needs Ansible itself pip3 install ansible-lint Usage The usage is fairly simple, just run ansible-lint <your-playbook> . The tool will check your playbook for best-practices, it traverses your playbook and will lint all included playbooks and roles. Take a look at the ansible-lint documentation for additional information. Lint in Docker Image The following Dockerfile can be used to build a Docker Container image which bundles ansible-lint and its dependencies: Dockerfile FROM python:3.9-slim # Enable colored output ENV TERM xterm-256color # Defining Ansible environment variable to not output depreaction warnings. This is not useful in the linting container. # This overwrites the value in the ansible.cfg from volume mount ENV ANSIBLE_DEPRECATION_WARNINGS = false # Install requirements. RUN apt-get update && apt-get install -y \\ git \\ && rm -rf /var/lib/apt/lists/* # Update pip RUN python3 -m pip install --no-cache-dir --no-compile --upgrade pip # Install ansible-lint and dependencies RUN pip3 install --no-cache-dir --no-compile ansible-lint ansible yamllint WORKDIR /data ENTRYPOINT [ \"ansible-lint\" ] CMD [ \"--version\" ] Build the container image, the command expects that the Dockerfile is present in the current directory: docker build -t ansible-lint . After building the image, the image can be used. Inside of the Ansible project directory, run this command (e.g. this lints the site.yml playbook). docker run --rm -v $( pwd ) :/data ansible-lint site.yml The output for example is something like this, ansible-lint reports a warning regarding unnecessary white-spaces in a line, as well as an error regarding unset file permissions (fix could be setting mode: 0644 in the task): $ docker run --rm -v $( pwd ) :/data ansible-lint site.yml WARNING Overriding detected file kind 'yaml' with 'playbook' for given positional argument: site.yml WARNING Listing 2 violation ( s ) that are fatal yaml: trailing spaces ( trailing-spaces ) roles/network/tasks/cacheserve-loopback-interface.yml:19 risky-file-permissions: File permissions unset or incorrect roles/network/tasks/cacheserve-loopback-interface.yml:43 Task/Handler: Deploy loopback interface config for Cacheserve You can skip specific rules or tags by adding them to your configuration file: # .ansible-lint warn_list: # or 'skip_list' to silence them completely - experimental # all rules tagged as experimental - yaml # Violations reported by yamllint Finished with 1 failure ( s ) , 1 warning ( s ) on 460 files. To simplify the usage, consider adding an alias to your .bashrc , e.g.: # .bashrc # User specific aliases and functions alias lint = \"docker run --rm -v $( pwd ) :/data ansible-lint\" After running source ~/.bashrc you can use the alias: lint site.yml Automated Linting Lining can and should be done automatically, this way you can't forget to check your playbook for best practices. This can be done on multiple levels, either locally as part of your Git workflow, as well as with a pipeline in your remote repository. Git pre-commit hook A nice way to check for best practices during your Git worflow is the usage of a pre-commit hook. These hooks can be simple bash script, which are run whenever you are commiting changes locally to the staging area. The following script can be used as a starting point, it uses ansible-lint from inside a container (see Lint in Docker Image how to build it) and also checks for unencrypted files in your commit. .git/hooks/pre-commit #!/bin/bash # # File should be .git/hooks/pre-commit and executable # # Pre-commit hook that runs ansible-lint Container for best practice checking # If lint has errors, commit will fail with an error message. if [[ ! $( docker inspect ansible-lint ) ]] ; then echo \"# DOCKER IMAGE NOT FOUND\" echo \"# Build the Docker image from the Gitlab project 'ansible-lint Docker Image'.\" echo \"# No linting is done!\" else echo \"# Running 'ansible-lint' against commit, this takes some time ...\" # Getting all files currently staged and storing them in variable FILES_TO_LINT = $( git diff --cached --name-only ) # Running with shared profile, see https://ansible-lint.readthedocs.io/profiles/ if [ -z \" $FILES_TO_LINT \" ] ; then echo \"# No files linting found. Add files to staging area with 'git add <file>'.\" else docker run --rm -v $( pwd ) :/data ansible-lint $FILES_TO_LINT if [ ! $? = 0 ] ; then echo \"# COMMIT REJECTED\" echo \"# Please fix the shown linting errors\" echo \"# (or force the commit with '--no-verify').\" exit 1 ; fi fi fi # Pre-commit hook that verifies if all files containing 'vault' in the name # are encrypted. # If not, commit will fail with an error message. # Finds all files in 'inventory' folder or 'files' folder in roles. Files in other # locations are not recognized! FILES_PATTERN = '(inventory.*vault.*)|(files.*vault.*)' REQUIRED = 'ANSIBLE_VAULT' EXIT_STATUS = 0 wipe = \"\\033[1m\\033[0m\" yellow = '\\033[1;33m' # carriage return hack. Leave it on 2 lines. cr = ' ' echo \"# Checking for unencrypted vault files in commit ...\" for f in $( git diff --cached --name-only | grep -E $FILES_PATTERN ) do # test for the presence of the required bit. MATCH = ` head -n1 $f | grep --no-messages $REQUIRED ` if [ ! $MATCH ] ; then # Build the list of unencrypted files if any UNENCRYPTED_FILES = \" $f$cr$UNENCRYPTED_FILES \" EXIT_STATUS = 1 fi done if [ ! $EXIT_STATUS = 0 ] ; then echo '# COMMIT REJECTED' echo '# Looks like unencrypted ansible-vault files are part of the commit:' echo '#' while read -r line ; do if [ -n \" $line \" ] ; then echo -e \"#\\t ${ yellow } unencrypted: $line ${ wipe } \" fi done <<< \" $UNENCRYPTED_FILES \" echo '#' echo \"# Please encrypt them with 'ansible-vault encrypt <file>'\" echo \"# (or force the commit with '--no-verify').\" exit $EXIT_STATUS fi exit $EXIT_STATUS CI Pipeline Running ansible-lint through a CI pipeline automatically when merging changes to the Git repository is highly advisable . A possible pipeline in Gitlab may look like this, utilizing the container image above: workflow : rules : - if : $CI_PIPELINE_SOURCE == 'merge_request_event' - if : $CI_PIPELINE_SOURCE == 'web' - if : $CI_PIPELINE_SOURCE == 'schedule' variables : GIT_STRATEGY : clone stages : - prepare - syntax - lint prepare : stage : prepare script : - 'echo -e \"### Prepare playbook execution. ###\"' - 'cp ansible.cfg.sample-lab ansible.cfg' - 'echo -e \"$VAULT_PASSWORD\" > .vault-password' artifacts : paths : - ansible.cfg - .vault-password cache : paths : - ansible.cfg - .vault-password tags : - ansible-lint syntax-check : stage : syntax script : - 'echo -e \"Perform a syntax check on the playbook. ###\"' - 'docker run --rm --entrypoint ansible-playbook -v $(pwd):/data ansible-lint site.yml --syntax-check' cache : paths : - ansible.cfg - .vault-password dependencies : - prepare tags : - ansible-lint ansible-lint : stage : lint script : - 'echo -e \"### Check for best practices with ansible-lint. ###\"' - 'echo -e \"### Using ansible-lint version: ###\"' - 'docker run --rm -v $(pwd):/data ansible-lint' - 'docker run --rm -v $(pwd):/data ansible-lint site.yml' cache : paths : - ansible.cfg - .vault-password dependencies : - prepare tags : - ansible-lint If you want to utilize the installed ansible and ansible-lint utilities on the host running the Gitlab Runner change the commands in the syntax stage to ansible-playbook site.yml --syntax-check and in the lint stage to ansible-lint --version and ansible-lint site.yml .","title":"Linting"},{"location":"development/linting/#linting","text":"Ansible Lint is a best-practice checker for Ansible, maintained by the Ansible community.","title":"Linting"},{"location":"development/linting/#installation","text":"Ansible Lint is installed through the Python packet manager: Note Ansible Lint always needs Ansible itself pip3 install ansible-lint","title":"Installation"},{"location":"development/linting/#usage","text":"The usage is fairly simple, just run ansible-lint <your-playbook> . The tool will check your playbook for best-practices, it traverses your playbook and will lint all included playbooks and roles. Take a look at the ansible-lint documentation for additional information.","title":"Usage"},{"location":"development/linting/#lint-in-docker-image","text":"The following Dockerfile can be used to build a Docker Container image which bundles ansible-lint and its dependencies: Dockerfile FROM python:3.9-slim # Enable colored output ENV TERM xterm-256color # Defining Ansible environment variable to not output depreaction warnings. This is not useful in the linting container. # This overwrites the value in the ansible.cfg from volume mount ENV ANSIBLE_DEPRECATION_WARNINGS = false # Install requirements. RUN apt-get update && apt-get install -y \\ git \\ && rm -rf /var/lib/apt/lists/* # Update pip RUN python3 -m pip install --no-cache-dir --no-compile --upgrade pip # Install ansible-lint and dependencies RUN pip3 install --no-cache-dir --no-compile ansible-lint ansible yamllint WORKDIR /data ENTRYPOINT [ \"ansible-lint\" ] CMD [ \"--version\" ] Build the container image, the command expects that the Dockerfile is present in the current directory: docker build -t ansible-lint . After building the image, the image can be used. Inside of the Ansible project directory, run this command (e.g. this lints the site.yml playbook). docker run --rm -v $( pwd ) :/data ansible-lint site.yml The output for example is something like this, ansible-lint reports a warning regarding unnecessary white-spaces in a line, as well as an error regarding unset file permissions (fix could be setting mode: 0644 in the task): $ docker run --rm -v $( pwd ) :/data ansible-lint site.yml WARNING Overriding detected file kind 'yaml' with 'playbook' for given positional argument: site.yml WARNING Listing 2 violation ( s ) that are fatal yaml: trailing spaces ( trailing-spaces ) roles/network/tasks/cacheserve-loopback-interface.yml:19 risky-file-permissions: File permissions unset or incorrect roles/network/tasks/cacheserve-loopback-interface.yml:43 Task/Handler: Deploy loopback interface config for Cacheserve You can skip specific rules or tags by adding them to your configuration file: # .ansible-lint warn_list: # or 'skip_list' to silence them completely - experimental # all rules tagged as experimental - yaml # Violations reported by yamllint Finished with 1 failure ( s ) , 1 warning ( s ) on 460 files. To simplify the usage, consider adding an alias to your .bashrc , e.g.: # .bashrc # User specific aliases and functions alias lint = \"docker run --rm -v $( pwd ) :/data ansible-lint\" After running source ~/.bashrc you can use the alias: lint site.yml","title":"Lint in Docker Image"},{"location":"development/linting/#automated-linting","text":"Lining can and should be done automatically, this way you can't forget to check your playbook for best practices. This can be done on multiple levels, either locally as part of your Git workflow, as well as with a pipeline in your remote repository.","title":"Automated Linting"},{"location":"development/linting/#git-pre-commit-hook","text":"A nice way to check for best practices during your Git worflow is the usage of a pre-commit hook. These hooks can be simple bash script, which are run whenever you are commiting changes locally to the staging area. The following script can be used as a starting point, it uses ansible-lint from inside a container (see Lint in Docker Image how to build it) and also checks for unencrypted files in your commit. .git/hooks/pre-commit #!/bin/bash # # File should be .git/hooks/pre-commit and executable # # Pre-commit hook that runs ansible-lint Container for best practice checking # If lint has errors, commit will fail with an error message. if [[ ! $( docker inspect ansible-lint ) ]] ; then echo \"# DOCKER IMAGE NOT FOUND\" echo \"# Build the Docker image from the Gitlab project 'ansible-lint Docker Image'.\" echo \"# No linting is done!\" else echo \"# Running 'ansible-lint' against commit, this takes some time ...\" # Getting all files currently staged and storing them in variable FILES_TO_LINT = $( git diff --cached --name-only ) # Running with shared profile, see https://ansible-lint.readthedocs.io/profiles/ if [ -z \" $FILES_TO_LINT \" ] ; then echo \"# No files linting found. Add files to staging area with 'git add <file>'.\" else docker run --rm -v $( pwd ) :/data ansible-lint $FILES_TO_LINT if [ ! $? = 0 ] ; then echo \"# COMMIT REJECTED\" echo \"# Please fix the shown linting errors\" echo \"# (or force the commit with '--no-verify').\" exit 1 ; fi fi fi # Pre-commit hook that verifies if all files containing 'vault' in the name # are encrypted. # If not, commit will fail with an error message. # Finds all files in 'inventory' folder or 'files' folder in roles. Files in other # locations are not recognized! FILES_PATTERN = '(inventory.*vault.*)|(files.*vault.*)' REQUIRED = 'ANSIBLE_VAULT' EXIT_STATUS = 0 wipe = \"\\033[1m\\033[0m\" yellow = '\\033[1;33m' # carriage return hack. Leave it on 2 lines. cr = ' ' echo \"# Checking for unencrypted vault files in commit ...\" for f in $( git diff --cached --name-only | grep -E $FILES_PATTERN ) do # test for the presence of the required bit. MATCH = ` head -n1 $f | grep --no-messages $REQUIRED ` if [ ! $MATCH ] ; then # Build the list of unencrypted files if any UNENCRYPTED_FILES = \" $f$cr$UNENCRYPTED_FILES \" EXIT_STATUS = 1 fi done if [ ! $EXIT_STATUS = 0 ] ; then echo '# COMMIT REJECTED' echo '# Looks like unencrypted ansible-vault files are part of the commit:' echo '#' while read -r line ; do if [ -n \" $line \" ] ; then echo -e \"#\\t ${ yellow } unencrypted: $line ${ wipe } \" fi done <<< \" $UNENCRYPTED_FILES \" echo '#' echo \"# Please encrypt them with 'ansible-vault encrypt <file>'\" echo \"# (or force the commit with '--no-verify').\" exit $EXIT_STATUS fi exit $EXIT_STATUS","title":"Git pre-commit hook"},{"location":"development/linting/#ci-pipeline","text":"Running ansible-lint through a CI pipeline automatically when merging changes to the Git repository is highly advisable . A possible pipeline in Gitlab may look like this, utilizing the container image above: workflow : rules : - if : $CI_PIPELINE_SOURCE == 'merge_request_event' - if : $CI_PIPELINE_SOURCE == 'web' - if : $CI_PIPELINE_SOURCE == 'schedule' variables : GIT_STRATEGY : clone stages : - prepare - syntax - lint prepare : stage : prepare script : - 'echo -e \"### Prepare playbook execution. ###\"' - 'cp ansible.cfg.sample-lab ansible.cfg' - 'echo -e \"$VAULT_PASSWORD\" > .vault-password' artifacts : paths : - ansible.cfg - .vault-password cache : paths : - ansible.cfg - .vault-password tags : - ansible-lint syntax-check : stage : syntax script : - 'echo -e \"Perform a syntax check on the playbook. ###\"' - 'docker run --rm --entrypoint ansible-playbook -v $(pwd):/data ansible-lint site.yml --syntax-check' cache : paths : - ansible.cfg - .vault-password dependencies : - prepare tags : - ansible-lint ansible-lint : stage : lint script : - 'echo -e \"### Check for best practices with ansible-lint. ###\"' - 'echo -e \"### Using ansible-lint version: ###\"' - 'docker run --rm -v $(pwd):/data ansible-lint' - 'docker run --rm -v $(pwd):/data ansible-lint site.yml' cache : paths : - ansible.cfg - .vault-password dependencies : - prepare tags : - ansible-lint If you want to utilize the installed ansible and ansible-lint utilities on the host running the Gitlab Runner change the commands in the syntax stage to ansible-playbook site.yml --syntax-check and in the lint stage to ansible-lint --version and ansible-lint site.yml .","title":"CI Pipeline"},{"location":"development/testing/","text":"Testing With many people contributing to the automation, it is crucial to test the automation content in-depth. So when you\u2019re developing new Ansible Content like playbooks, roles and collections, it\u2019s a good idea to test the content in a test environment before using it to automate production infrastructure. Testing ensures the automation works as designed and avoids unpleasant surprises down the road. Testing automation content is often a challenge, since it requires the deployment of specific testing infrastructure as well as setting up the testing conditions to ensure the tests are relevant. Consider the following list for testing your Ansible content, with increasing complexity: yamllint ansible-playbook --syntax-check ansible-lint molecule test ansible-playbook --check ( against production ) Parallel infrastructure Syntax check The whole playbook (and all roles and tasks) need to, minimally, pass a basic ansible-playbook syntax check run. ansible-playbook main.yml --syntax-check Running this as a step in a CI Pipeline is advisable. Molecule Molecule project is designed to aid in the development and testing of Ansible roles, provides support for testing with multiple instances, operating systems and distributions, virtualization providers, test frameworks and testing scenarios. Molecule is mostly used to test roles in isolation (although it is possible to test multiple roles or playbooks at once). To test against a fresh system, molecule uses Docker to provision virtualized test hosts, run commands on them and assert the success. Molecule does not connect via ssh to the container, instead it uses an Ansible installation inside the container. It is therefor necessary to use a custom build container image. Take a look at the Molecule documentation for a full overview. Installation The described configuration below expects the Docker container runtime on the Ansible Controller (other drivers are available), the binary and dependencies are installed through the Python package manager . Use a Python Virtual environment (requires the python3-venv package) to encapsulate the installation from the rest of your Controller. python3 -m venv molecule-venv Activate the VE: source molecule-virtualenv/bin/activate Install dependencies (an own Ansible is necessary, ansible-lint is optional, but useful): pip3 install --upgrade pip pip3 install ansible-core pip3 install molecule pip3 install molecule-docker pip3 install ansible-lint Note Currently (21.05.2022), there is a bug when trying to login with molecule login command. Use version 3.5.2 of the molecule package! This is fixed in version 4.0.3, update if possible. Python package molecule-docker requires the modules of the community.docker collection. When you only installed ansible-core , you'll need to install the collection separately: ansible-galaxy collection install community.docker Use deactivate to leave your VE. Configuration You may use these example configurations as a starting point. It expects that the Docker image is already present (use docker pull timgrt/centos7-ansible ) and ansible-lint is installed. See the install instructions above. The molecule configuration files are kept in the role folder you want to test. Create the directory molecule/default and at least the molecule.yml and converge.yml : roles/ \u2514\u2500\u2500 webserver-demo \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 molecule \u2502 \u2514\u2500\u2500 default \u2502 \u251c\u2500\u2500 converge.yml \u2502 \u2514\u2500\u2500 molecule.yml \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 templates \u2514\u2500\u2500 index.html Central Molecule configuration Playbook file Preparation stage Verification molecule.yml --- driver : name : docker platforms : # (1)! - name : instance1 # (2)! groups : # (3)! - molecule image : timgrt/centos7-ansible:latest # (4)! tmpfs : - /run - /tmp volumes : - /sys/fs/cgroup:/sys/fs/cgroup:ro privileged : true command : \"/usr/sbin/init\" pre_build_image : true # (5)! provisioner : name : ansible options : D : true # (6)! connection_options : ansible_user : ansible # (7)! config_options : defaults : interpreter_python : auto_silent callbacks_enabled : profile_tasks, timer, yaml # (8)! inventory : links : group_vars : ../../../../inventory/group_vars/ # (9)! lint : | # (10)! set -e ansible-lint . scenario : # (11)! create_sequence : - create - prepare converge_sequence : - create - prepare - converge - lint test_sequence : - destroy - create - converge - idempotence - lint - destroy destroy_sequence : - destroy List of hosts to provision by molecule , copy the list item and use a unique name if you want to deploy multiple containers. The name of your container, for better identification you could use e.g. demo.${USER}.molecule which uses your username from environment variable substitution, showing who deployed the container for what purpose. Additional groups the host should be part of, using a custom molecule group for referencing in converge.yml . If you want your container to inherit variables from group_vars (see inventory.links.group_vars in the provisioner section), add the group(s) to this list. For more information regarding the used container image, see https://hub.docker.com/r/timgrt/centos7-ansible Container image must be present before running Molecule, pull it with docker pull timgrt/centos7-ansible Enables diff mode, set to false if you don't want that. Uses the ansible user to connect to the container (defined in the container image), this way you can test with become . Otherwise you would connect with the root user, most likely this is not what you would do in production. Adds a timer to every task and the overall playbook run, as well as formatting the Ansible output to YAML for better readability. Install necessary collections with ansible-galaxy collection install ansible.posix community.general . If you want your container to inherit variables from group_vars , reference the location of your group_vars (here they are stored in the subfolder inventory of the project, searching begins in the scenario folder defaults ). Delete the inventory key and all content if you don't need this. This runs the Best-Practice checker ansible-lint in the converge and test sequence, must be installed separately, see Linting for more information. A scenario allows Molecule to test a role in a particular way, these are the stages when executing Molecule. For example, running molecule converge would create a container (if not already created), prepare it (if not already prepared), run the converge stage and lint the role. Remove the list items you don't need if necessary. converge.yml The role to test must be defined here, change role-name to the actual name. --- - name : Converge hosts : molecule become : true roles : - role-name prepare.yml Adds an optional preparation stage (referenced by prepare in the scenario definition). For example, if you want to test SSH Key-Pair creation in your container (this is also used by the user module to create SSH keys), install the necessary packages before running the role itself. --- - name : Prepare hosts : molecule become : true tasks : - name : Install OpenSSH for ssh-keygen ansible.builtin.yum : name : openssh state : present Remember, you are using a Docker image, not every package from the distribution is installed by default to minimze the image size. verify.yml Adds an optional verification stage (referenced by verify in the scenario definition). Not used in the example above. Add this block to your molecule.yml as a top-level key: verifier : name : ansible The verify.yml contains your tests for your role. --- - name : Verify hosts : molecule become : true tasks : - name : Get service facts ansible.builtin.service_facts : # Service may have started, returning 'OK' in the service module, but may have failed later. - name : Ensure that MariaDB is in running state assert : that : - ansible_facts['services']['mariadb.service']['state'] == 'running' Other verifiers like testinfra can be used. Usage Molecule is executed from within the role you want to test, change directory: cd roles/webserver-demo From here, run the molecule scenario. To only create the defined containers, but not run the Ansible tasks: molecule create To run the Ansible tasks of the role (if the container does not exist, it will be created): molecule converge To execute a full test circle (existing containers are deleted, re-created and Ansible tasks are executed, containers are deleted(!) afterwards): molecule test","title":"Testing"},{"location":"development/testing/#testing","text":"With many people contributing to the automation, it is crucial to test the automation content in-depth. So when you\u2019re developing new Ansible Content like playbooks, roles and collections, it\u2019s a good idea to test the content in a test environment before using it to automate production infrastructure. Testing ensures the automation works as designed and avoids unpleasant surprises down the road. Testing automation content is often a challenge, since it requires the deployment of specific testing infrastructure as well as setting up the testing conditions to ensure the tests are relevant. Consider the following list for testing your Ansible content, with increasing complexity: yamllint ansible-playbook --syntax-check ansible-lint molecule test ansible-playbook --check ( against production ) Parallel infrastructure","title":"Testing"},{"location":"development/testing/#syntax-check","text":"The whole playbook (and all roles and tasks) need to, minimally, pass a basic ansible-playbook syntax check run. ansible-playbook main.yml --syntax-check Running this as a step in a CI Pipeline is advisable.","title":"Syntax check"},{"location":"development/testing/#molecule","text":"Molecule project is designed to aid in the development and testing of Ansible roles, provides support for testing with multiple instances, operating systems and distributions, virtualization providers, test frameworks and testing scenarios. Molecule is mostly used to test roles in isolation (although it is possible to test multiple roles or playbooks at once). To test against a fresh system, molecule uses Docker to provision virtualized test hosts, run commands on them and assert the success. Molecule does not connect via ssh to the container, instead it uses an Ansible installation inside the container. It is therefor necessary to use a custom build container image. Take a look at the Molecule documentation for a full overview.","title":"Molecule"},{"location":"development/testing/#installation","text":"The described configuration below expects the Docker container runtime on the Ansible Controller (other drivers are available), the binary and dependencies are installed through the Python package manager . Use a Python Virtual environment (requires the python3-venv package) to encapsulate the installation from the rest of your Controller. python3 -m venv molecule-venv Activate the VE: source molecule-virtualenv/bin/activate Install dependencies (an own Ansible is necessary, ansible-lint is optional, but useful): pip3 install --upgrade pip pip3 install ansible-core pip3 install molecule pip3 install molecule-docker pip3 install ansible-lint Note Currently (21.05.2022), there is a bug when trying to login with molecule login command. Use version 3.5.2 of the molecule package! This is fixed in version 4.0.3, update if possible. Python package molecule-docker requires the modules of the community.docker collection. When you only installed ansible-core , you'll need to install the collection separately: ansible-galaxy collection install community.docker Use deactivate to leave your VE.","title":"Installation"},{"location":"development/testing/#configuration","text":"You may use these example configurations as a starting point. It expects that the Docker image is already present (use docker pull timgrt/centos7-ansible ) and ansible-lint is installed. See the install instructions above. The molecule configuration files are kept in the role folder you want to test. Create the directory molecule/default and at least the molecule.yml and converge.yml : roles/ \u2514\u2500\u2500 webserver-demo \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 molecule \u2502 \u2514\u2500\u2500 default \u2502 \u251c\u2500\u2500 converge.yml \u2502 \u2514\u2500\u2500 molecule.yml \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 templates \u2514\u2500\u2500 index.html Central Molecule configuration Playbook file Preparation stage Verification molecule.yml --- driver : name : docker platforms : # (1)! - name : instance1 # (2)! groups : # (3)! - molecule image : timgrt/centos7-ansible:latest # (4)! tmpfs : - /run - /tmp volumes : - /sys/fs/cgroup:/sys/fs/cgroup:ro privileged : true command : \"/usr/sbin/init\" pre_build_image : true # (5)! provisioner : name : ansible options : D : true # (6)! connection_options : ansible_user : ansible # (7)! config_options : defaults : interpreter_python : auto_silent callbacks_enabled : profile_tasks, timer, yaml # (8)! inventory : links : group_vars : ../../../../inventory/group_vars/ # (9)! lint : | # (10)! set -e ansible-lint . scenario : # (11)! create_sequence : - create - prepare converge_sequence : - create - prepare - converge - lint test_sequence : - destroy - create - converge - idempotence - lint - destroy destroy_sequence : - destroy List of hosts to provision by molecule , copy the list item and use a unique name if you want to deploy multiple containers. The name of your container, for better identification you could use e.g. demo.${USER}.molecule which uses your username from environment variable substitution, showing who deployed the container for what purpose. Additional groups the host should be part of, using a custom molecule group for referencing in converge.yml . If you want your container to inherit variables from group_vars (see inventory.links.group_vars in the provisioner section), add the group(s) to this list. For more information regarding the used container image, see https://hub.docker.com/r/timgrt/centos7-ansible Container image must be present before running Molecule, pull it with docker pull timgrt/centos7-ansible Enables diff mode, set to false if you don't want that. Uses the ansible user to connect to the container (defined in the container image), this way you can test with become . Otherwise you would connect with the root user, most likely this is not what you would do in production. Adds a timer to every task and the overall playbook run, as well as formatting the Ansible output to YAML for better readability. Install necessary collections with ansible-galaxy collection install ansible.posix community.general . If you want your container to inherit variables from group_vars , reference the location of your group_vars (here they are stored in the subfolder inventory of the project, searching begins in the scenario folder defaults ). Delete the inventory key and all content if you don't need this. This runs the Best-Practice checker ansible-lint in the converge and test sequence, must be installed separately, see Linting for more information. A scenario allows Molecule to test a role in a particular way, these are the stages when executing Molecule. For example, running molecule converge would create a container (if not already created), prepare it (if not already prepared), run the converge stage and lint the role. Remove the list items you don't need if necessary. converge.yml The role to test must be defined here, change role-name to the actual name. --- - name : Converge hosts : molecule become : true roles : - role-name prepare.yml Adds an optional preparation stage (referenced by prepare in the scenario definition). For example, if you want to test SSH Key-Pair creation in your container (this is also used by the user module to create SSH keys), install the necessary packages before running the role itself. --- - name : Prepare hosts : molecule become : true tasks : - name : Install OpenSSH for ssh-keygen ansible.builtin.yum : name : openssh state : present Remember, you are using a Docker image, not every package from the distribution is installed by default to minimze the image size. verify.yml Adds an optional verification stage (referenced by verify in the scenario definition). Not used in the example above. Add this block to your molecule.yml as a top-level key: verifier : name : ansible The verify.yml contains your tests for your role. --- - name : Verify hosts : molecule become : true tasks : - name : Get service facts ansible.builtin.service_facts : # Service may have started, returning 'OK' in the service module, but may have failed later. - name : Ensure that MariaDB is in running state assert : that : - ansible_facts['services']['mariadb.service']['state'] == 'running' Other verifiers like testinfra can be used.","title":"Configuration"},{"location":"development/testing/#usage","text":"Molecule is executed from within the role you want to test, change directory: cd roles/webserver-demo From here, run the molecule scenario. To only create the defined containers, but not run the Ansible tasks: molecule create To run the Ansible tasks of the role (if the container does not exist, it will be created): molecule converge To execute a full test circle (existing containers are deleted, re-created and Ansible tasks are executed, containers are deleted(!) afterwards): molecule test","title":"Usage"}]}